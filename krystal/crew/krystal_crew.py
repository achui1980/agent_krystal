"""
Krystal Crew - End-to-End Testing Crew

Orchestrates 5 agents to execute complete testing workflow:
1. Generate test data â†’ 2. Upload to SFTP â†’ 3. Trigger process â†’ 4. Poll for completion â†’ 5. Validate results
"""

import logging
from datetime import datetime
from typing import Dict, Any, List
import uuid

from crewai import Crew, Task, Process
from crewai.llm import LLM

from krystal.agents import (
    DataGeneratorAgent,
    SFTPOperatorAgent,
    APITriggerAgent,
    PollingMonitorAgent,
    ResultValidatorAgent,
)
from krystal.config import ServiceConfig, SFTPConfig, KrystalConfig


logger = logging.getLogger(__name__)


class KrystalCrew:
    """End-to-end testing crew for a single service"""

    def __init__(
        self,
        service_config: ServiceConfig,
        sftp_config: SFTPConfig,
        environment: str = "dev",
        llm=None,
    ):
        """
        Initialize Krystal Crew for a service

        Args:
            service_config: Configuration for the service to test
            sftp_config: SFTP connection configuration
            environment: Current environment name
            llm: Language model to use (optional)
        """
        self.service_config = service_config
        self.sftp_config = sftp_config
        self.environment = environment
        self.batch_id = (
            f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        )

        # Initialize LLM if not provided
        if llm is None:
            import os
            from crewai.llm import LLM

            # Set up proxy if configured (before creating LLM)
            https_proxy = os.getenv("HTTPS_PROXY") or os.getenv("https_proxy")
            http_proxy = os.getenv("HTTP_PROXY") or os.getenv("http_proxy")
            proxy_url = https_proxy or http_proxy

            if proxy_url:
                # Set proxy environment variables for OpenAI client
                os.environ["HTTP_PROXY"] = proxy_url
                os.environ["HTTPS_PROXY"] = proxy_url
                # For OpenAI Python client v1.x
                os.environ["OPENAI_PROXY"] = proxy_url

            llm = LLM(
                model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                api_key=os.getenv("OPENAI_API_KEY"),
            )
        self.llm = llm

        # Build environment context
        self.environment_context = f"""
å½“å‰æ‰§è¡Œç¯å¢ƒ: {environment}
æœåŠ¡åç§°: {service_config.name}
æ‰¹æ¬¡ID: {self.batch_id}
SFTPæœåŠ¡å™¨: {sftp_config.host}:{sftp_config.port}
"""

        # Store results
        self.results: Dict[str, Any] = {}

    def create_crew(self) -> Crew:
        """Create and configure the Crew with all agents and tasks"""
        # Create agents
        data_generator = DataGeneratorAgent.create(self.llm, self.environment_context)
        sftp_operator = SFTPOperatorAgent.create(self.llm, self.environment_context)
        api_trigger = APITriggerAgent.create(self.llm, self.environment_context)
        polling_monitor = PollingMonitorAgent.create(self.llm, self.environment_context)
        result_validator = ResultValidatorAgent.create(
            self.llm, self.environment_context
        )

        # Create tasks sequentially with proper context
        generate_task = self._create_generate_task(data_generator)
        upload_task = self._create_upload_task(sftp_operator, generate_task)
        trigger_task = self._create_trigger_task(api_trigger, upload_task)
        poll_task = self._create_poll_task(polling_monitor, trigger_task)
        validate_task = self._create_validate_task(result_validator, poll_task)

        # Create crew with sequential process
        crew = Crew(
            agents=[
                data_generator,
                sftp_operator,
                api_trigger,
                polling_monitor,
                result_validator,
            ],
            tasks=[
                generate_task,
                upload_task,
                trigger_task,
                poll_task,
                validate_task,
            ],
            process=Process.sequential,
            verbose=True,
        )

        return crew

    def _create_generate_task(self, agent) -> Task:
        """Create data generation task"""
        data_gen = self.service_config.data_generation

        # Build data schema description
        schema_fields = []
        for field in data_gen.data_schema:
            field_desc = f"- {field.name} ({field.type})"
            if field.values:
                field_desc += f", values: {field.values}"
            if field.pattern:
                field_desc += f", pattern: {field.pattern}"
            schema_fields.append(field_desc)

        description = f"""
ç”Ÿæˆæµ‹è¯•æ•°æ®CSVæ–‡ä»¶ç”¨äºæœåŠ¡: {self.service_config.name}

æ•°æ®ç”Ÿæˆé…ç½®:
- è¾“å‡ºè¡Œæ•°: {data_gen.row_count}
- è¾“å‡ºæ–‡ä»¶å: {data_gen.output_filename}
- æ¨¡æ¿è·¯å¾„: {data_gen.template or "æœªæŒ‡å®šï¼ˆä½¿ç”¨schemaç”Ÿæˆï¼‰"}

æ•°æ®æ¨¡å¼å®šä¹‰:
{chr(10).join(schema_fields)}

æ‰¹æ¬¡ID: {self.batch_id}

è¯·ä½¿ç”¨csv_generatorå·¥å…·ç”Ÿæˆæ•°æ®:
1. å¦‚æœæœ‰æ¨¡æ¿ï¼Œä½¿ç”¨æ¨¡æ¿è·¯å¾„
2. å¦‚æœæ²¡æœ‰æ¨¡æ¿ï¼Œæ ¹æ®data_schemaç”Ÿæˆ
3. ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•: /tmp/krystal/{self.service_config.name}/
4. æ–‡ä»¶åä¸­åŒ…å«æ‰¹æ¬¡ID

é¢„æœŸè¾“å‡º:
- ç”Ÿæˆçš„CSVæ–‡ä»¶å®Œæ•´è·¯å¾„
        """

        return Task(
            description=description,
            expected_output="ç”Ÿæˆçš„CSVæ–‡ä»¶å®Œæ•´è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰",
            agent=agent,
        )

    def _create_upload_task(self, agent, generate_task: Task) -> Task:
        """Create SFTP upload task"""
        upload = self.service_config.upload

        description = f"""
å°†ç”Ÿæˆçš„CSVæ–‡ä»¶ä¸Šä¼ åˆ°SFTPæœåŠ¡å™¨ã€‚

SFTPé…ç½®:
- æœåŠ¡å™¨: {self.sftp_config.host}:{self.sftp_config.port}
- ç”¨æˆ·å: {self.sftp_config.username}
- å¯†ç : ä»ç¯å¢ƒå˜é‡ SFTP_PASSWORD è·å–
- è¿œç¨‹åŸºç¡€è·¯å¾„: {self.sftp_config.remote_base_path}

ä¸Šä¼ é…ç½®:
- è¿œç¨‹è·¯å¾„: {upload.get("remote_path", "/uploads")}
- æœåŠ¡åç§°: {self.service_config.name}

æ‰¹æ¬¡ID: {self.batch_id}

è¯·ä½¿ç”¨sftp_clientå·¥å…·ä¸Šä¼ æ–‡ä»¶:
1. è¿æ¥SFTPæœåŠ¡å™¨ï¼ˆä½¿ç”¨ä¸Šè¿°é…ç½®å’ŒSFTP_PASSWORDç¯å¢ƒå˜é‡ä¸­çš„å¯†ç ï¼‰
2. ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨
3. ä¸Šä¼ æ–‡ä»¶åˆ°è¿œç¨‹è·¯å¾„
4. éªŒè¯æ–‡ä»¶å¤§å°
5. è¿”å›è¿œç¨‹æ–‡ä»¶å®Œæ•´è·¯å¾„

æ³¨æ„: æ–‡ä»¶è·¯å¾„ä»ä¸Šä¸€æ­¥ä»»åŠ¡ä¸­è·å–ï¼ˆcontextä¼ é€’ï¼‰
        """

        return Task(
            description=description,
            expected_output="è¿œç¨‹æ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œä¸Šä¼ ç¡®è®¤ä¿¡æ¯",
            agent=agent,
            context=[generate_task],
        )

    def _create_trigger_task(self, agent, upload_task: Task) -> Task:
        """Create API trigger task"""
        trigger = self.service_config.trigger

        # Build headers description
        headers_desc = "\n".join([f"  {k}: {v}" for k, v in trigger.headers.items()])

        description = f"""
è°ƒç”¨APIè§¦å‘ä¸šåŠ¡æµç¨‹ã€‚

APIè§¦å‘é…ç½®:
- ç«¯ç‚¹: {trigger.endpoint}
- æ–¹æ³•: {trigger.method}
- è¯·æ±‚å¤´:
{headers_desc}

è¯·æ±‚ä½“æ¨¡æ¿:
```
{trigger.body_template}
```

ä»»åŠ¡IDæå–å™¨: {trigger.task_id_extractor}

æ‰¹æ¬¡ID: {self.batch_id}

å˜é‡æ›¿æ¢:
- {{remote_file_path}} - ä»ä¸Šä¼ ä»»åŠ¡è·å–
- {{batch_id}} - ä½¿ç”¨å½“å‰æ‰¹æ¬¡ID: {self.batch_id}
- {{row_count}} - æ•°æ®è¡Œæ•°: {self.service_config.data_generation.row_count}

è¯·ä½¿ç”¨api_clientå’Œtemplate_rendererå·¥å…·:
1. æ¸²æŸ“æ¨¡æ¿ï¼Œæ›¿æ¢å˜é‡
2. å‘é€HTTPè¯·æ±‚
3. ä»å“åº”ä¸­æå–ä»»åŠ¡IDï¼ˆä½¿ç”¨json_extractorï¼‰
4. è¿”å›ä»»åŠ¡IDå’Œå“åº”è¯¦æƒ…
        """

        return Task(
            description=description,
            expected_output="ä»»åŠ¡IDï¼ˆç”¨äºåç»­è½®è¯¢ï¼‰å’ŒAPIå“åº”è¯¦æƒ…",
            agent=agent,
            context=[upload_task],
        )

    def _create_poll_task(self, agent, trigger_task: Task) -> Task:
        """Create polling task"""
        polling = self.service_config.polling

        if not polling.enabled:
            return Task(
                description="è½®è¯¢å·²ç¦ç”¨ï¼Œè·³è¿‡æ­¤æ­¥éª¤ã€‚",
                expected_output="è½®è¯¢è·³è¿‡ç¡®è®¤",
                agent=agent,
                context=[trigger_task],
            )

        description = f"""
è½®è¯¢æ£€æŸ¥ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ç›´åˆ°å®Œæˆã€‚

è½®è¯¢é…ç½®:
- æœ€å¤§å°è¯•æ¬¡æ•°: {polling.max_attempts}
- è½®è¯¢é—´éš”: {polling.interval}ç§’
- æˆåŠŸçŠ¶æ€: {", ".join(polling.success_statuses)}
- å¤±è´¥çŠ¶æ€: {", ".join(polling.failure_statuses)}

çŠ¶æ€æ£€æŸ¥ç«¯ç‚¹: {polling.status_check_endpoint or "ä½¿ç”¨ä¸è§¦å‘ç›¸åŒçš„ç«¯ç‚¹"}

ä»»åŠ¡ID: ä»è§¦å‘ä»»åŠ¡è·å–

è¯·ä½¿ç”¨polling_serviceå·¥å…·:
1. å®šæœŸæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
2. åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç»ˆæ€ï¼ˆæˆåŠŸ/å¤±è´¥/è¶…æ—¶ï¼‰
3. è®°å½•å°è¯•æ¬¡æ•°å’Œè€—æ—¶
4. è¿”å›æœ€ç»ˆçŠ¶æ€å’Œè¯¦ç»†ä¿¡æ¯

æ³¨æ„:
- çŠ¶æ€æ£€æŸ¥ç«¯ç‚¹å¯èƒ½åŒ…å« {{task_id}} å ä½ç¬¦ï¼Œéœ€è¦æ›¿æ¢
- ä½¿ç”¨jsonpathæå–çŠ¶æ€å­—æ®µ
- æ­£ç¡®å¤„ç†è¶…æ—¶æƒ…å†µ
        """

        return Task(
            description=description,
            expected_output="æœ€ç»ˆä»»åŠ¡çŠ¶æ€ã€å°è¯•æ¬¡æ•°ã€å®Œæˆæ—¶é—´",
            agent=agent,
            context=[trigger_task],
        )

    def _create_validate_task(self, agent, poll_task: Task) -> Task:
        """Create result validation task"""
        validation = self.service_config.validation

        description = f"""
ä¸‹è½½ç»“æœæ–‡ä»¶å¹¶éªŒè¯æ•°æ®æ­£ç¡®æ€§ã€‚

SFTPé…ç½®:
- æœåŠ¡å™¨: {self.sftp_config.host}:{self.sftp_config.port}
- ç”¨æˆ·å: {self.sftp_config.username}
- è¿œç¨‹åŸºç¡€è·¯å¾„: {self.sftp_config.remote_base_path}

éªŒè¯é…ç½®:
- ä¸‹è½½ç»“æœæ–‡ä»¶: {"æ˜¯" if validation.download_from_sftp else "å¦"}
- è¿œç¨‹ç»“æœè·¯å¾„: {validation.remote_result_path}
- æœ¬åœ°ä¸´æ—¶è·¯å¾„: {validation.local_temp_path}
- å¯¹æ¯”æ¨¡å¼: {validation.comparison_mode}

æ‰¹æ¬¡ID: {self.batch_id}

è¿œç¨‹è·¯å¾„å˜é‡:
- {{batch_id}} - æ›¿æ¢ä¸ºå½“å‰æ‰¹æ¬¡ID: {self.batch_id}

è¯·ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ‰§è¡ŒéªŒè¯:
1. sftp_client (å¦‚æœéœ€è¦ä¸‹è½½)
   - æ“ä½œç±»å‹: download
   - æœåŠ¡å™¨: {self.sftp_config.host}:{self.sftp_config.port}
   - ç”¨æˆ·å: {self.sftp_config.username}
   - å¯†ç : ä»ç¯å¢ƒå˜é‡ SFTP_PASSWORD è·å–
   - ä»è¿œç¨‹è·¯å¾„ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°ä¸´æ—¶è·¯å¾„

2. file_validator
   - éªŒè¯æ–‡ä»¶å­˜åœ¨
   - éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœ‰é…ç½®ï¼‰

3. data_validator (å¦‚æœæ˜¯CSVå¯¹æ¯”æ¨¡å¼)
   - å¯¹æ¯”é¢„æœŸå’Œå®é™…æ•°æ®
   - åº”ç”¨éªŒè¯è§„åˆ™
   - ç”Ÿæˆå·®å¼‚æŠ¥å‘Š

é¢„æœŸè¾“å‡º:
è¯¦ç»†çš„éªŒè¯æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
- æµ‹è¯•é€šè¿‡/å¤±è´¥çŠ¶æ€
- éªŒè¯è¯¦æƒ…
- é”™è¯¯åˆ—è¡¨
- æ•°æ®è¡Œæ•°ç»Ÿè®¡
        """

        return Task(
            description=description,
            expected_output="è¯¦ç»†çš„æµ‹è¯•éªŒè¯æŠ¥å‘Šï¼ˆJSONæ ¼å¼ï¼‰",
            agent=agent,
            context=[poll_task],
        )

    def run(self) -> Dict[str, Any]:
        """
        Execute the testing workflow

        Returns:
            Dictionary with execution results
        """
        import os
        from dotenv import load_dotenv
        import sys
        from io import StringIO

        load_dotenv()

        logger.info(f"{'=' * 70}")
        logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•æœåŠ¡: {self.service_config.name}")
        logger.info(f"ğŸŒ ç¯å¢ƒ: {self.environment}")
        logger.info(f"ğŸ“¦ æ‰¹æ¬¡ID: {self.batch_id}")
        logger.info(f"{'=' * 70}")

        # æ•è· CrewAI çš„è¯¦ç»†è¾“å‡º
        crew_output = StringIO()
        original_stdout = sys.stdout

        try:
            # Create and run crew
            logger.info("ğŸ”§ æ­£åœ¨åˆ›å»º CrewAI Agents...")
            crew = self.create_crew()
            logger.info(f"   âœ“ åˆ›å»ºäº† {len(crew.agents)} ä¸ª Agents")
            logger.info(f"   âœ“ é…ç½®äº† {len(crew.tasks)} ä¸ª Tasks")
            logger.info(
                f"   âœ“ ä½¿ç”¨æ¨¡å‹: {self.llm.model if hasattr(self.llm, 'model') else 'default'}"
            )

            logger.info("ğŸ¬ å¯åŠ¨ CrewAI Workflow æ‰§è¡Œ...")
            logger.info(f"   æµç¨‹: æ•°æ®ç”Ÿæˆ â†’ SFTPä¸Šä¼  â†’ APIè§¦å‘ â†’ è½®è¯¢ â†’ éªŒè¯")

            # é‡å®šå‘ stdout æ¥æ•è·è¾“å‡º
            sys.stdout = crew_output
            result = crew.kickoff()
            sys.stdout = original_stdout

            # æ‰“å°æ•è·çš„è¾“å‡º
            output_content = crew_output.getvalue()
            if output_content:
                logger.info("=" * 70)
                logger.info("ğŸ“‹ CrewAI æ‰§è¡Œè¯¦ç»†æ—¥å¿—:")
                logger.info("=" * 70)
                for line in output_content.split("\n"):
                    if line.strip():
                        logger.info(line)
                logger.info("=" * 70)

            # Parse result
            self.results = {
                "service": self.service_config.name,
                "batch_id": self.batch_id,
                "environment": self.environment,
                "success": True,
                "result": result,
                "timestamp": datetime.now().isoformat(),
                "crew_output": output_content,
            }

            logger.info(f"âœ… æœåŠ¡ {self.service_config.name} æµ‹è¯•å®Œæˆ")
            logger.info(f"   æ‰¹æ¬¡ID: {self.batch_id}")
            logger.info(f"   ç»“æœç±»å‹: {type(result).__name__}")
            logger.info(f"{'=' * 70}")

            return self.results

        except Exception as e:
            sys.stdout = original_stdout
            crew_output_str = crew_output.getvalue()

            logger.error(f"âŒ æœåŠ¡ {self.service_config.name} æµ‹è¯•å¤±è´¥")
            logger.error(f"   é”™è¯¯: {str(e)}")
            if crew_output_str:
                logger.error(f"ğŸ“‹ æ‰§è¡Œæ—¥å¿—ï¼ˆåˆ°å‡ºé”™ç‚¹ï¼‰:")
                for line in (
                    crew_output_str[-1000:]
                    if len(crew_output_str) > 1000
                    else crew_output_str
                ).split("\n"):
                    if line.strip():
                        logger.error(line)

            self.results = {
                "service": self.service_config.name,
                "batch_id": self.batch_id,
                "environment": self.environment,
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "crew_output": crew_output_str,
            }

            logger.error(f"{'=' * 60}")
            logger.error(f"æœåŠ¡ {self.service_config.name} æµ‹è¯•å¤±è´¥")
            logger.error(f"é”™è¯¯: {str(e)}")
            logger.error(f"{'=' * 60}")

            return self.results
