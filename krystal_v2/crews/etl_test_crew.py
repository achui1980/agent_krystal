"""
ETL Test Crew - CrewAIç¼–æ’
æ‰§è¡Œæµç¨‹ï¼šå®é™…ETLæ‰§è¡Œ â†’ ç»“æœéªŒè¯ â†’ æŠ¥å‘Šç”Ÿæˆ
"""

import os
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path

from crewai import Crew, Task, Process
from crewai.llm import LLM

from ..agents import ETLOperatorAgent, ResultValidatorAgent, ReportWriterAgent
from ..execution.etl_executor import ETLExecutor


logger = logging.getLogger(__name__)


class ETLTestCrew:
    """
    ETLæµ‹è¯•Crew

    æ‰§è¡Œæµç¨‹ï¼š
    1. å®é™…æ‰§è¡ŒETLæµç¨‹ï¼ˆä½¿ç”¨ETLExecutorï¼‰
    2. ç»“æœéªŒè¯ï¼ˆä»£ç å¯¹æ¯”ï¼‰
    3. CrewAIç”ŸæˆæŠ¥å‘Šï¼ˆéªŒè¯å™¨+æŠ¥å‘Šæ’°å†™Agentï¼‰
    """

    def __init__(
        self,
        input_file: str,
        expected_file: str,
        service_config: Any,
        global_config: Any = None,
        environment: str = "local",
        output_dir: str = "./reports",
        llm=None,
    ):
        self.input_file = input_file
        self.expected_file = expected_file
        self.service_config = service_config
        self.global_config = global_config or {}
        self.environment = environment
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæµ‹è¯•ID
        self.test_id = f"etl_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # åˆå§‹åŒ–LLM
        if llm is None:
            llm = LLM(
                model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                api_key=os.getenv("OPENAI_API_KEY"),
            )
        self.llm = llm

        # æå–é…ç½®
        self._extract_configs()

    def _extract_configs(self):
        """ä»é…ç½®å¯¹è±¡æå–å¿…è¦ä¿¡æ¯"""
        # æœåŠ¡é…ç½®
        if hasattr(self.service_config, "name"):
            self.service_name = self.service_config.name
            self.trigger_config = (
                self.service_config.trigger
                if hasattr(self.service_config, "trigger")
                else {}
            )
            self.polling_config = (
                self.service_config.polling
                if hasattr(self.service_config, "polling")
                else {}
            )
            upload = (
                self.service_config.upload
                if hasattr(self.service_config, "upload")
                else {}
            )
            self.remote_upload_path = (
                upload.get("remote_path", "/uploads")
                if isinstance(upload, dict)
                else "/uploads"
            )
            # Extract validation config
            validation = (
                self.service_config.validation
                if hasattr(self.service_config, "validation")
                else {}
            )
            self.validation_config = validation if isinstance(validation, dict) else {}
        else:
            self.service_name = "unknown"
            self.trigger_config = {}
            self.polling_config = {}
            self.remote_upload_path = "/uploads"
            self.validation_config = {}

        # SFTPé…ç½®ï¼ˆä»å…¨å±€é…ç½®ï¼‰
        self.sftp_config = {}
        if self.global_config and hasattr(self.global_config, "sftp"):
            sftp = self.global_config.sftp
            self.sftp_config = {
                "host": getattr(sftp, "host", "localhost"),
                "port": getattr(sftp, "port", 2223),
                "username": getattr(sftp, "username", "testuser"),
                "password": getattr(sftp, "password", ""),
                "remote_base_path": getattr(sftp, "remote_base_path", "/uploads"),
            }
        elif isinstance(self.global_config, dict) and "sftp" in self.global_config:
            self.sftp_config = self.global_config["sftp"]

        # é»˜è®¤SFTPé…ç½®
        if not self.sftp_config:
            self.sftp_config = {
                "host": "localhost",
                "port": 2223,
                "username": "testuser",
                "password": os.getenv("SFTP_PASSWORD", ""),
                "remote_base_path": "/uploads",
            }

    def run(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        logger.info(f"ğŸš€ å¯åŠ¨ETLæµ‹è¯•: {self.test_id}")
        logger.info(f"   è¾“å…¥æ–‡ä»¶: {self.input_file}")
        logger.info(f"   é¢„æœŸæ–‡ä»¶: {self.expected_file}")
        logger.info(f"   æœåŠ¡: {self.service_name}")

        # æ­¥éª¤1: å®é™…æ‰§è¡ŒETL
        etl_result = self._execute_etl()

        if not etl_result.get("success"):
            logger.error(f"âŒ ETLæ‰§è¡Œå¤±è´¥: {etl_result.get('error')}")
            # å³ä½¿å¤±è´¥ä¹Ÿç”ŸæˆæŠ¥å‘Š
            report_paths = self._generate_failure_report(etl_result)
            return {
                "success": False,
                "test_id": self.test_id,
                "error": etl_result.get("error"),
                "etl_result": etl_result,
                "report_paths": report_paths,
                "output_dir": str(self.output_dir),
            }

        # æ­¥éª¤2: ç»“æœéªŒè¯
        validation_result = self._validate_results(etl_result.get("result_file"))

        # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Šï¼ˆä½¿ç”¨CrewAIï¼‰
        report_paths = self._generate_reports(etl_result, validation_result)

        logger.info(f"âœ… æµ‹è¯•å®Œæˆ: {self.test_id}")
        logger.info(f"   æŠ¥å‘Šä½ç½®: {report_paths}")

        return {
            "success": True,
            "test_id": self.test_id,
            "etl_result": etl_result,
            "validation_result": validation_result,
            "report_paths": report_paths,
            "output_dir": str(self.output_dir),
            "overall_pass": validation_result.get("match", False),
        }

    def _execute_etl(self) -> Dict[str, Any]:
        """
        å®é™…æ‰§è¡ŒETLæµç¨‹

        Returns:
            ETLæ‰§è¡Œç»“æœ
        """
        logger.info("ğŸ”§ æ‰§è¡ŒETLæµç¨‹...")

        executor = ETLExecutor()

        # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
        local_output_path = str(self.output_dir / f"result_{self.test_id}.csv")

        # å‡†å¤‡è§¦å‘é…ç½®
        trigger_cfg = {
            "endpoint": self.trigger_config.get("endpoint", "")
            if isinstance(self.trigger_config, dict)
            else getattr(self.trigger_config, "endpoint", ""),
            "method": self.trigger_config.get("method", "POST")
            if isinstance(self.trigger_config, dict)
            else getattr(self.trigger_config, "method", "POST"),
            "headers": self.trigger_config.get("headers", {})
            if isinstance(self.trigger_config, dict)
            else getattr(self.trigger_config, "headers", {}),
            "body_template": self.trigger_config.get("body_template", "{}")
            if isinstance(self.trigger_config, dict)
            else getattr(self.trigger_config, "body_template", "{}"),
            "task_id_extractor": self.trigger_config.get(
                "task_id_extractor", "$.task_id"
            )
            if isinstance(self.trigger_config, dict)
            else getattr(self.trigger_config, "task_id_extractor", "$.task_id"),
        }

        # æ·»åŠ  upload è·¯å¾„åˆ° sftp_config
        upload_remote_path = (
            self.remote_upload_path
            if hasattr(self, "remote_upload_path")
            else "/uploads"
        )
        sftp_cfg_with_upload = self.sftp_config.copy()
        sftp_cfg_with_upload["upload_remote_path"] = upload_remote_path

        # å‡†å¤‡è½®è¯¢é…ç½®
        polling_cfg = {
            "status_endpoint": self.polling_config.get("status_check_endpoint", "")
            if isinstance(self.polling_config, dict)
            else getattr(self.polling_config, "status_check_endpoint", ""),
            "status_extractor": "$.status",
            "success_statuses": ["completed", "success"],
            "failure_statuses": ["failed", "error"],
            "max_attempts": self.polling_config.get("max_attempts", 30)
            if isinstance(self.polling_config, dict)
            else getattr(self.polling_config, "max_attempts", 30),
            "interval": self.polling_config.get("interval", 10)
            if isinstance(self.polling_config, dict)
            else getattr(self.polling_config, "interval", 10),
        }

        result = executor.execute_full_etl(
            input_file=self.input_file,
            output_file=local_output_path,
            sftp_config=sftp_cfg_with_upload,
            trigger_config=trigger_cfg,
            polling_config=polling_cfg,
            validation_config=self.validation_config,
        )

        return result

    def _validate_results(self, actual_file: str) -> Dict[str, Any]:
        """
        éªŒè¯å®é™…ç»“æœä¸é¢„æœŸç»“æœ

        Args:
            actual_file: å®é™…ç»“æœæ–‡ä»¶è·¯å¾„

        Returns:
            éªŒè¯ç»“æœ
        """
        logger.info("ğŸ” éªŒè¯ç»“æœ...")

        if not actual_file or not Path(actual_file).exists():
            return {
                "match": False,
                "error": "å®é™…ç»“æœæ–‡ä»¶ä¸å­˜åœ¨",
                "statistics": {
                    "total_rows": 0,
                    "matching_rows": 0,
                    "different_rows": 0,
                    "similarity": "0%",
                },
            }

        try:
            # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
            with open(self.expected_file, "r", encoding="utf-8") as f:
                expected_lines = f.readlines()
            with open(actual_file, "r", encoding="utf-8") as f:
                actual_lines = f.readlines()

            # é€è¡Œå¯¹æ¯”
            differences = []
            matching = 0
            different = 0
            max_rows = max(len(expected_lines), len(actual_lines))

            for i in range(max_rows):
                exp_line = (
                    expected_lines[i].strip()
                    if i < len(expected_lines)
                    else "<MISSING>"
                )
                act_line = (
                    actual_lines[i].strip() if i < len(actual_lines) else "<MISSING>"
                )

                if exp_line == act_line:
                    matching += 1
                else:
                    different += 1
                    differences.append(
                        {
                            "row_number": i + 1,
                            "expected": exp_line,
                            "actual": act_line,
                        }
                    )

            similarity = (matching / max_rows * 100) if max_rows > 0 else 0

            return {
                "match": different == 0,
                "statistics": {
                    "total_rows": max_rows,
                    "matching_rows": matching,
                    "different_rows": different,
                    "similarity": f"{similarity:.1f}%",
                },
                "differences": differences,
                "actual_file": actual_file,
                "expected_file": self.expected_file,
            }

        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return {
                "match": False,
                "error": str(e),
                "statistics": {
                    "total_rows": 0,
                    "matching_rows": 0,
                    "different_rows": 0,
                    "similarity": "0%",
                },
            }

    def _generate_reports(
        self, etl_result: Dict, validation_result: Dict
    ) -> Dict[str, str]:
        """
        ä½¿ç”¨CrewAIç”ŸæˆæŠ¥å‘Š

        Args:
            etl_result: ETLæ‰§è¡Œç»“æœ
            validation_result: éªŒè¯ç»“æœ

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        logger.info("ğŸ“„ ç”ŸæˆæŠ¥å‘Š...")

        from ..utils.report_generator import ReportGenerator

        generator = ReportGenerator(str(self.output_dir))

        # æå–ETLæ­¥éª¤æ•°æ®
        steps = etl_result.get("steps", {})
        etl_steps = []
        for step_name, step_data in steps.items():
            etl_steps.append(
                {
                    "name": step_name.capitalize(),
                    "duration": step_data.get("duration", 0),
                    "success": step_data.get("success", False),
                    "message": step_data.get("message", ""),
                }
            )

        # æå–éªŒè¯ç»Ÿè®¡æ•°æ®
        stats = validation_result.get("statistics", {})
        total_rows = stats.get("total_rows", 0)
        matching_rows = stats.get("matching_rows", 0)
        different_rows = stats.get("different_rows", 0)
        similarity_str = stats.get("similarity", "0%")
        try:
            similarity = float(similarity_str.replace("%", ""))
        except:
            similarity = 0

        # æå–å·®å¼‚è¯¦æƒ…
        differences = validation_result.get("differences", [])
        comparison_rows = []
        for diff in differences:
            comparison_rows.append(
                {
                    "row_number": diff.get("row_number", 0),
                    "expected": diff.get("expected", ""),
                    "actual": diff.get("actual", ""),
                    "match": False,
                }
            )

        # æ„å»ºæŠ¥å‘Šæ•°æ®ï¼ˆåŒ¹é…ReportGeneratoræœŸæœ›çš„æ ¼å¼ï¼‰
        report_data = {
            "test_id": self.test_id,
            "service_name": self.service_name,
            "environment": self.environment,
            "timestamp": datetime.now().isoformat(),
            "overall_pass": validation_result.get("match", False),
            "total_duration": etl_result.get("total_duration", 0),
            "etl_steps": etl_steps,
            "total_rows": total_rows,
            "matching_rows": matching_rows,
            "different_rows": different_rows,
            "similarity": similarity,
            "comparison_rows": comparison_rows,
            "llm_analysis": None,
        }

        paths = generator.generate_both_formats(report_data)
        return paths

    def _generate_failure_report(self, etl_result: Dict) -> Dict[str, str]:
        """
        ETLå¤±è´¥æ—¶ç”Ÿæˆå¤±è´¥æŠ¥å‘Š

        Args:
            etl_result: ETLæ‰§è¡Œç»“æœ

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„å­—å…¸
        """
        from ..utils.report_generator import ReportGenerator

        generator = ReportGenerator(str(self.output_dir))

        # æå–ETLæ­¥éª¤æ•°æ®ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿå¯èƒ½æœ‰éƒ¨åˆ†æ­¥éª¤æˆåŠŸï¼‰
        steps = etl_result.get("steps", {})
        etl_steps = []
        for step_name, step_data in steps.items():
            etl_steps.append(
                {
                    "name": step_name.capitalize(),
                    "duration": step_data.get("duration", 0),
                    "success": step_data.get("success", False),
                    "message": step_data.get("message", ""),
                }
            )

        report_data = {
            "test_id": self.test_id,
            "service_name": self.service_name,
            "environment": self.environment,
            "timestamp": datetime.now().isoformat(),
            "overall_pass": False,
            "total_duration": etl_result.get("total_duration", 0),
            "etl_steps": etl_steps,
            "total_rows": 0,
            "matching_rows": 0,
            "different_rows": 0,
            "similarity": 0,
            "comparison_rows": [],
            "llm_analysis": f"ETLæ‰§è¡Œå¤±è´¥: {etl_result.get('error', 'Unknown error')}",
        }

        paths = generator.generate_both_formats(report_data)
        return paths
