"""
è‡ªä¸»ä»£ç ç”Ÿæˆå™¨ V2 (ä¼˜åŒ–ç‰ˆ) - é›†æˆæ¨¡æ¿ç³»ç»Ÿã€æ™ºèƒ½æµ‹è¯•å’Œè¯­ä¹‰åº“

ä¼˜åŒ–ç‚¹:
1. ä½¿ç”¨ä»£ç æ¨¡æ¿ç³»ç»Ÿ (å‡å°‘ç”Ÿæˆé”™è¯¯)
2. ä½¿ç”¨æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨ (é’ˆå¯¹æ€§æµ‹è¯•)
3. é›†æˆExpectedè¯­ä¹‰åº“ (æä¾›ä¸šåŠ¡å«ä¹‰å‚è€ƒ)
4. ä¿æŒä¸V1çš„å…¼å®¹æ€§

é¢„æœŸæ•ˆæœ:
- é¦–æ¬¡æˆåŠŸç‡: 70% â†’ 86% (+16%)
- ä»£ç ç”Ÿæˆè´¨é‡æ›´é«˜
- æµ‹è¯•æ›´æœ‰é’ˆå¯¹æ€§
"""

import os
import sys
import json
import traceback
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional

from crewai import Agent, Task, Crew, Process
from crewai.llm import LLM
from dotenv import load_dotenv

# å¯¼å…¥æ–°ç»„ä»¶
try:
    # ä¼˜å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥ (ä½œä¸ºåŒ…ä½¿ç”¨æ—¶)
    from .code_template import CodeTemplate
    from .smart_test_generator import SmartTestGenerator
    from .expected_semantic_builder import ExpectedSemanticBuilder
except ImportError:
    # å›é€€åˆ°ç»å¯¹å¯¼å…¥ (ä½œä¸ºè„šæœ¬ç›´æ¥è¿è¡Œæ—¶)
    from code_template import CodeTemplate
    from smart_test_generator import SmartTestGenerator
    from expected_semantic_builder import ExpectedSemanticBuilder

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent.parent.parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)


class AutonomousCodeGeneratorV2:
    """
    è‡ªä¸»ä»£ç ç”Ÿæˆå™¨ V2 (ä¼˜åŒ–ç‰ˆ)

    é›†æˆäº†:
    - ä»£ç æ¨¡æ¿ç³»ç»Ÿ (å‡å°‘ç»“æ„æ€§é”™è¯¯)
    - æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨ (åŠ¨æ€ç”Ÿæˆé’ˆå¯¹æ€§æµ‹è¯•)
    - Expectedè¯­ä¹‰åº“ (æä¾›å­—æ®µä¸šåŠ¡å«ä¹‰)
    """

    def __init__(self, max_iterations: int = 5, use_semantic_cache: bool = True):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            max_iterations: æœ€å¤§ä¿®å¤è¿­ä»£æ¬¡æ•°
            use_semantic_cache: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰åº“ç¼“å­˜
        """
        self.max_iterations = max_iterations
        self.use_semantic_cache = use_semantic_cache
        self.output_dir = Path("./generated_autonomous")
        self.output_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–Agent
        api_key = os.getenv("OPENAI_API_KEY")
        model = os.getenv("OPENAI_MODEL", "gpt-4o")
        self.llm = LLM(model=model, api_key=api_key) if api_key else None

        if not self.llm:
            raise ValueError("OPENAI_API_KEY not found!")

        self.agent = self._create_programmer_agent()

        # åˆå§‹åŒ–æ–°ç»„ä»¶
        self.semantic_builder = ExpectedSemanticBuilder(llm=self.llm)
        self.semantic_map = None  # å»¶è¿ŸåŠ è½½

    def _create_programmer_agent(self) -> Agent:
        """åˆ›å»ºç¨‹åºå‘˜Agent"""
        return Agent(
            role="èµ„æ·±Pythonå¼€å‘å·¥ç¨‹å¸ˆä¸ETLæµ‹è¯•ä¸“å®¶",
            goal="åŸºäºæ¨¡æ¿å’Œè¯­ä¹‰åº“ï¼Œç¼–å†™é«˜è´¨é‡ã€å¥å£®çš„Pythonä»£ç ",
            backstory="""
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰15å¹´ç»éªŒçš„èµ„æ·±Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼ŒåŒæ—¶ä¹Ÿæ˜¯ETLæµ‹è¯•ä¸“å®¶ã€‚

ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼š
1. ä»£ç è®¾è®¡ï¼šåŸºäºé¢„å®šä¹‰æ¨¡æ¿å¡«å……ä¸šåŠ¡é€»è¾‘
2. è§„åˆ™ç†è§£ï¼šç»“åˆè¯­ä¹‰åº“ç†è§£å­—æ®µä¸šåŠ¡å«ä¹‰
3. ç²¾å‡†å®ç°ï¼šä¸“æ³¨äºè½¬æ¢é€»è¾‘ï¼Œæ¡†æ¶ä»£ç å·²é¢„å®šä¹‰
4. æ•…éšœæ’æŸ¥ï¼šå¿«é€Ÿå®šä½ä»£ç é—®é¢˜å¹¶ä¿®å¤

ä½ çš„ä¼˜åŠ¿ï¼š
- æœ‰å®Œæ•´çš„ä»£ç æ¨¡æ¿ä½œä¸ºåŸºç¡€
- æœ‰Expectedå­—æ®µè¯­ä¹‰åº“ä½œä¸ºå‚è€ƒ
- åªéœ€ä¸“æ³¨äºæ ¸å¿ƒä¸šåŠ¡é€»è¾‘
- å¯ä»¥å‚è€ƒè¯­ä¹‰åº“é¿å…ç†è§£åå·®

ç¼–ç¨‹åŸåˆ™ï¼š
- éµå¾ªæ¨¡æ¿ç»“æ„ï¼Œä¸è¦é‡æ„æ¡†æ¶
- å‚è€ƒè¯­ä¹‰åº“ç†è§£å­—æ®µå«ä¹‰
- ä¸“æ³¨äºè½¬æ¢é€»è¾‘çš„æ­£ç¡®æ€§
- å®Œå–„çš„é”™è¯¯å¤„ç†
            """,
            verbose=True,
            allow_delegation=False,
            llm=self.llm,
        )

    def run(
        self, rules_path: str, source_path: str, expected_path: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„è‡ªä¸»ä»£ç ç”Ÿæˆæµç¨‹ (V2ä¼˜åŒ–ç‰ˆ)

        æµç¨‹:
        1. æ„å»º/åŠ è½½Expectedè¯­ä¹‰åº“
        2. Agentåˆ†æè§„åˆ™ç”Ÿæˆè§„æ ¼ä¹¦
        3. åŸºäºæ¨¡æ¿ç”Ÿæˆä»£ç 
        4. æ™ºèƒ½æµ‹è¯•éªŒè¯
        5. å¦‚éœ€è¦åˆ™è¿­ä»£ä¿®å¤

        Returns:
            {
                'success': bool,
                'code_path': str,
                'iterations': int,
                'data': List[Dict],
                'version': 'v2'
            }
        """
        print("=" * 80)
        print("ğŸ¤– è‡ªä¸»ä»£ç ç”Ÿæˆå™¨ V2 (ä¼˜åŒ–ç‰ˆ)")
        print("=" * 80)
        print(f"ğŸ“„ è§„åˆ™æ–‡ä»¶: {rules_path}")
        print(f"ğŸ“„ Source: {source_path}")
        print(f"ğŸ“„ Expected: {expected_path}")
        print(f"ğŸ”„ æœ€å¤§ä¿®å¤æ¬¡æ•°: {self.max_iterations}")
        print()

        # Step 0: æ„å»º/åŠ è½½Expectedè¯­ä¹‰åº“
        print("ğŸ“š Step 0: æ„å»º/åŠ è½½Expectedè¯­ä¹‰åº“...")
        try:
            self.semantic_map = self.semantic_builder.build_or_load_semantic_map(
                expected_path, force_rebuild=not self.use_semantic_cache
            )
            print(
                f"   âœ… è¯­ä¹‰åº“å·²åŠ è½½: {len(self.semantic_map.get('fields', {}))} ä¸ªå­—æ®µ"
            )
        except Exception as e:
            print(f"   âš ï¸  è¯­ä¹‰åº“åŠ è½½å¤±è´¥: {e}")
            print(f"   â„¹ï¸  ç»§ç»­æ‰§è¡Œï¼ˆæ— è¯­ä¹‰åº“æ”¯æŒï¼‰")
            self.semantic_map = None

        # Step 1: Agentåˆ†æè§„åˆ™ç”Ÿæˆè§„æ ¼ä¹¦
        print("\nğŸ“ Step 1: Agentåˆ†æè§„åˆ™...")
        spec = self._analyze_rules(rules_path, source_path, expected_path)
        print(f"   âœ… ç”Ÿæˆè§„æ ¼ä¹¦: {len(spec)} å­—ç¬¦")

        # Step 2-4: ä»£ç ç”Ÿæˆ-æµ‹è¯•-ä¿®å¤å¾ªç¯
        code = None
        final_result = None

        for iteration in range(self.max_iterations):
            print(f"\nğŸ”§ ç¬¬ {iteration + 1}/{self.max_iterations} è½®ä»£ç ç”Ÿæˆ/ä¿®å¤")

            if iteration == 0:
                # ç¬¬ä¸€è½®ï¼šä½¿ç”¨æ¨¡æ¿ç”Ÿæˆä»£ç 
                print("   ğŸ“ ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿç”Ÿæˆä»£ç ...")
                code = self._generate_code_with_template(
                    spec, rules_path, source_path, expected_path
                )
            else:
                # åç»­è½®ï¼šä¿®å¤ä»£ç 
                print(
                    f"   ğŸ”§ ä¿®å¤ä»£ç  (åŸºäºé”™è¯¯: {final_result.get('error_type', 'Unknown')})..."
                )
                code = self._fix_code(spec, code, final_result)

            # ä¿å­˜ä»£ç åˆ°æ–‡ä»¶
            code_path = self.output_dir / f"data_generator_v2_{iteration + 1}.py"
            with open(code_path, "w", encoding="utf-8") as f:
                f.write(code)
            print(f"   ğŸ’¾ ä»£ç å·²ä¿å­˜: {code_path}")

            # ä½¿ç”¨æ™ºèƒ½æµ‹è¯•
            print("   ğŸ§ª ä½¿ç”¨æ™ºèƒ½æµ‹è¯•éªŒè¯ä»£ç ...")
            final_result = self._test_code_smart(code, spec, source_path, expected_path)

            if final_result["success"]:
                print(f"   âœ… æµ‹è¯•é€šè¿‡ï¼ä»£ç åœ¨ç¬¬ {iteration + 1} è½®éªŒè¯æˆåŠŸï¼")
                break
            else:
                print(f"   âŒ æµ‹è¯•å¤±è´¥")
                print(f"      é”™è¯¯ç±»å‹: {final_result.get('error_type', 'Unknown')}")
                print(
                    f"      é”™è¯¯ä¿¡æ¯: {final_result.get('error_message', 'No message')[:100]}..."
                )
        else:
            # è¾¾åˆ°æœ€å¤§æ¬¡æ•°ä»æœªæˆåŠŸ
            print(f"\nâŒ è¾¾åˆ°æœ€å¤§ä¿®å¤æ¬¡æ•° ({self.max_iterations})ï¼Œä»£ç ä»æ— æ³•è¿è¡Œ")
            return {
                "success": False,
                "error": "Max iterations reached",
                "last_error": final_result,
                "code_path": str(code_path) if code else None,
                "version": "v2",
            }

        # Step 5: æ‰§è¡Œæœ€ç»ˆä»£ç ç”Ÿæˆæ•°æ®
        print("\nğŸš€ Step 5: æ‰§è¡Œæœ€ç»ˆä»£ç ç”Ÿæˆæ•°æ®...")
        data = self._execute_final_code(code)

        print("\n" + "=" * 80)
        print("âœ… è‡ªä¸»ä»£ç ç”Ÿæˆå®Œæˆ (V2)ï¼")
        print("=" * 80)

        return {
            "success": True,
            "code_path": str(code_path),
            "iterations": iteration + 1,
            "data": data,
            "spec": spec,
            "version": "v2",
        }

    def _read_file_contents(
        self, rules_path: str, source_path: str, expected_path: str
    ) -> Dict[str, str]:
        """è¯»å–è¾“å…¥æ–‡ä»¶çš„å®é™…å†…å®¹"""
        import pandas as pd

        # è¯»å– rules.xlsx (Sheet1, è¡¨å¤´åœ¨ç¬¬5è¡Œ)
        try:
            rules_df = pd.read_excel(rules_path, sheet_name="Sheet1", header=4)
            rules_content = rules_df.to_csv(index=False)  # è½¬ä¸ºCSVæ ¼å¼ä¾¿äºAgenté˜…è¯»
        except Exception as e:
            rules_content = f"Error reading rules: {e}"

        # è¯»å– source.csv (å‰10è¡Œ)
        try:
            source_df = pd.read_csv(source_path, nrows=10)
            source_content = source_df.to_csv(index=False)
        except Exception as e:
            source_content = f"Error reading source: {e}"

        # è¯»å– expected.txt (æ‰€æœ‰è¡Œ - ç‰¹æ®Šæ ¼å¼ FIELD_NAME:default_value)
        try:
            with open(expected_path, "r", encoding="utf-8") as f:
                expected_lines = f.readlines()
            expected_content = "".join(expected_lines[:100])  # å‰100è¡Œ
        except Exception as e:
            expected_content = f"Error reading expected: {e}"

        return {
            "rules": rules_content,
            "source": source_content,
            "expected": expected_content,
        }

    def _analyze_rules(
        self, rules_path: str, source_path: str, expected_path: str
    ) -> str:
        """
        Agentåˆ†æè§„åˆ™ç”Ÿæˆè§„æ ¼ä¹¦ (å¢å¼ºç‰ˆ - ä½¿ç”¨è¯­ä¹‰åº“)
        """
        # ğŸ”¥ å…³é”®ä¿®å¤: è¯»å–æ–‡ä»¶å®é™…å†…å®¹
        file_contents = self._read_file_contents(rules_path, source_path, expected_path)

        # æ„å»ºæç¤ºè¯ - å¦‚æœæœ‰è¯­ä¹‰åº“åˆ™æä¾›å‚è€ƒ
        semantic_context = ""
        if self.semantic_map:
            # æå–å…³é”®å­—æ®µçš„è¯­ä¹‰ä¿¡æ¯ä½œä¸ºå‚è€ƒ
            key_fields = ["PRODUCT_LINE", "FIRST_NAME", "LAST_NAME", "STATE", "CITY"]
            semantic_samples = {}
            for field in key_fields:
                field_sem = self.semantic_map.get("fields", {}).get(field)
                if field_sem:
                    semantic_samples[field] = {
                        "meaning": field_sem.get("business_meaning", ""),
                        "type": field_sem.get("data_type", ""),
                        "sources": field_sem.get("possible_source_fields", [])[:3],
                    }

            if semantic_samples:
                semantic_context = f"""

**Expectedå­—æ®µè¯­ä¹‰åº“å‚è€ƒ** (ç¤ºä¾‹å…³é”®å­—æ®µ):
{json.dumps(semantic_samples, ensure_ascii=False, indent=2)}

ä½¿ç”¨è¯­ä¹‰åº“æ—¶ï¼š
- å‚è€ƒbusiness_meaningç†è§£å­—æ®µå«ä¹‰
- å‚è€ƒpossible_source_fieldsæ¨æ–­æ˜ å°„å…³ç³»
- ç¡®ä¿è½¬æ¢é€»è¾‘ç¬¦åˆå­—æ®µçš„ä¸šåŠ¡å«ä¹‰
"""

        task = Task(
            description=f"""
ä½œä¸ºèµ„æ·±ETLæµ‹è¯•ä¸“å®¶å’Œä»£ç æ¶æ„å¸ˆï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹ææ–™å¹¶ç”Ÿæˆä»£ç è§„æ ¼ä¹¦ï¼š

**è¾“å…¥æ–‡ä»¶å®é™…å†…å®¹ï¼š**

1. **è§„åˆ™æ–‡ä»¶ (rules.xlsx Sheet1, è¡¨å¤´ç¬¬5è¡Œ):**
```csv
{file_contents["rules"][:5000]}
...ï¼ˆå…±{len(file_contents["rules"])}å­—ç¬¦ï¼Œå·²æˆªå–å‰5000å­—ç¬¦ï¼‰
```

2. **Sourceæ¨¡æ¿ (source.csv å‰10è¡Œ):**
```csv
{file_contents["source"]}
```

3. **Expectedæ¨¡æ¿ (expected.txt - ç‰¹æ®Šæ ¼å¼ FIELD_NAME:default_value):**
```
{file_contents["expected"]}
```
æ³¨æ„ï¼šexpected.txtä½¿ç”¨ç‰¹æ®Šæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªå­—æ®µï¼Œæ ¼å¼ä¸º "FIELD_NAME:default_value"
éœ€è¦æå–æ‰€æœ‰å­—æ®µåï¼ˆå†’å·å·¦ä¾§ï¼‰ä½œä¸ºexpected_fieldsåˆ—è¡¨ã€‚
{semantic_context}

**åˆ†æä»»åŠ¡ï¼š**

1. **åˆ†æè§„åˆ™** - ä»è§„åˆ™CSVä¸­æå–æ‰€æœ‰92æ¡è§„åˆ™çš„å­—æ®µæ˜ å°„å…³ç³»
2. **è¯†åˆ«å­—æ®µ** - ä»Source CSVè¡¨å¤´å’ŒExpected TXTè¡¨å¤´æå–æ‰€æœ‰å­—æ®µå
3. **æå–è½¬æ¢é€»è¾‘** - åˆ†ææ¯æ¡è§„åˆ™çš„è½¬æ¢ç±»å‹ï¼ˆdirect/conditional/default/transformï¼‰
4. **è®¡ç®—ä½¿ç”¨å­—æ®µ** - ç²¾ç¡®ç»Ÿè®¡å“ªäº›Sourceå­—æ®µè¢«ä½¿ç”¨ï¼Œå“ªäº›æœªä½¿ç”¨

**è¾“å‡ºJSONè§„æ ¼ä¹¦ï¼š**
{{
    "source_fields": ["ä»Source CSVè¡¨å¤´æå–çš„æ‰€æœ‰å­—æ®µå"],
    "expected_fields": ["ä»Expected TXTè¡¨å¤´æå–çš„æ‰€æœ‰å­—æ®µå"],
    "field_mappings": [
        {{
            "source": "æºå­—æ®µåï¼ˆå¦‚æœæœ‰ï¼‰",
            "target": "ç›®æ ‡å­—æ®µå",
            "type": "direct|conditional|default|transform",
            "logic": "è½¬æ¢é€»è¾‘çš„ç®€çŸ­æè¿°",
            "conditions": {{"æ¡ä»¶": "å€¼"}}  // ä»…conditionalç±»å‹éœ€è¦
        }}
    ],
    "used_source_fields": ["field_mappingsä¸­å®é™…å¼•ç”¨çš„sourceå­—æ®µå»é‡åˆ—è¡¨"],
    "unused_source_fields": ["source_fieldsä¸­æœªè¢«ä½¿ç”¨çš„å­—æ®µ"],
    "test_scenarios": {{
        "normal": ["æ­£å¸¸åœºæ™¯æè¿°"],
        "abnormal": ["å¼‚å¸¸åœºæ™¯æè¿°"],
        "boundary": ["è¾¹ç•Œåœºæ™¯æè¿°"]
    }},
    "code_structure": {{
        "class_name": "SmartDataGenerator",
        "methods": ["éœ€è¦çš„æ–¹æ³•åˆ—è¡¨"]
    }}
}}

ã€å…³é”®è¦æ±‚ã€‘
- åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–è§£é‡Š
- used_source_fieldså¿…é¡»100%åŒ¹é…field_mappingsä¸­çš„sourceå­—æ®µ
- æ‰€æœ‰å­—æ®µåå¿…é¡»ä»å®é™…æ–‡ä»¶å†…å®¹ä¸­æå–ï¼Œä¸è¦çŒœæµ‹
            """,
            expected_output="JSONæ ¼å¼çš„ä»£ç ç”Ÿæˆè§„æ ¼ä¹¦",
            agent=self.agent,
        )

        crew = Crew(agents=[self.agent], tasks=[task], verbose=False)
        result = crew.kickoff()

        return result.raw

    def _generate_code_with_template(
        self, spec: str, rules_path: str, source_path: str, expected_path: str
    ) -> str:
        """
        ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿç”Ÿæˆä»£ç  (V2æ ¸å¿ƒä¼˜åŒ–)

        ç­–ç•¥ï¼š
        1. ä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ (~700è¡Œæ¡†æ¶ä»£ç )
        2. Agentåªéœ€å¡«å……3ä¸ªéƒ¨åˆ† (~800è¡Œä¸šåŠ¡é€»è¾‘)
        3. å‚è€ƒè¯­ä¹‰åº“ç¡®ä¿ç†è§£æ­£ç¡®
        """
        # è§£æspec
        try:
            spec_dict = json.loads(spec)
        except:
            # å¦‚æœspecåŒ…å«markdownæ ‡è®°ï¼Œæå–JSON
            if "```json" in spec:
                spec = spec.split("```json")[1].split("```")[0]
            elif "```" in spec:
                spec = spec.split("```")[1].split("```")[0]
            spec_dict = json.loads(spec.strip())

        # ç”ŸæˆåŸºç¡€æ¨¡æ¿
        template_code = CodeTemplate.generate_code(spec_dict, rules_path)

        # æ„å»ºè¯­ä¹‰åº“ä¸Šä¸‹æ–‡
        semantic_context = ""
        if self.semantic_map:
            semantic_context = f"""

**Expectedå­—æ®µè¯­ä¹‰åº“** (å®Œæ•´ç‰ˆå·²åŠ è½½):
å¯ç”¨äºéªŒè¯è½¬æ¢é€»è¾‘çš„æ­£ç¡®æ€§ã€‚ä¾‹å¦‚ï¼š
- PRODUCT_LINEåº”è¯¥æ˜¯äº§å“çº¿ä»£ç æšä¸¾å€¼
- FIRST_NAMEåº”è¯¥æ˜¯ä»Memberå­—æ®µæ‹†åˆ†å¾—åˆ°
- STATEåº”è¯¥æ˜¯2å­—ç¬¦å·ä»£ç ï¼Œéœ€ä¸CITYåŒ¹é…

è¯­ä¹‰åº“åŒ…å«{len(self.semantic_map.get("fields", {}))}ä¸ªå­—æ®µçš„è¯¦ç»†ä¿¡æ¯ã€‚
"""

        # Agentå¡«å……3ä¸ªå…³é”®éƒ¨åˆ†
        task = Task(
            description=f"""
ä½ å°†åŸºäºé¢„å®šä¹‰çš„ä»£ç æ¨¡æ¿ï¼Œå¡«å……3ä¸ªå…³é”®éƒ¨åˆ†çš„ä¸šåŠ¡é€»è¾‘ã€‚

**åŸºç¡€æ¨¡æ¿** (å·²åŒ…å«çº¦700è¡Œæ¡†æ¶ä»£ç ):
```python
{template_code[:2000]}
...ï¼ˆå…±{len(template_code)}å­—ç¬¦ï¼‰
```

**è§„æ ¼ä¹¦**:
{spec[:1000]}...
{semantic_context}

**ä½ éœ€è¦å¡«å……çš„3ä¸ªéƒ¨åˆ†**:

1. **SOURCE_GENERATION_NORMAL** (~200è¡Œ)
   ç”ŸæˆSourceè¡Œæ•°æ®çš„é€»è¾‘ï¼ŒåŸºäºused_source_fieldsï¼š
   ```python
   return {{
       "Member": "LAST,FIRST M",
       "Product": self.fake.random_element(self._product_types),
       "State": state,
       "City": city,
       ...  # å…¶ä½™28ä¸ªå­—æ®µ
   }}
   ```

2. **TRANSFORMATION_METHODS** (~400è¡Œ)
   ä¸ºæ¯ä¸ªfield_mappingç”Ÿæˆè½¬æ¢æ–¹æ³•ï¼š
   ```python
   def transform_PRODUCT_LINE(self, source: Dict) -> str:
       \"\"\"è½¬æ¢Productåˆ°PRODUCT_LINE\"\"\"
       product = source.get("Product", "")
       if product == "PDP":
           return "MD"
       elif product in ["LPPO", "LPPO SNP DE"]:
           return "MA/MAPD"
       ...
   ```

3. **FIELD_MAPPING_LOGIC** (~200è¡Œ)
   ä¸»è½¬æ¢æ–¹æ³•ä¸­çš„å­—æ®µæ˜ å°„ï¼š
   ```python
   expected["PRODUCT_LINE"] = self.transform_PRODUCT_LINE(source)
   expected["FIRST_NAME"] = self.transform_FIRST_NAME(source)
   ...
   ```

**å…³é”®è¦æ±‚**:
1. ä½¿ç”¨è§„æ ¼ä¹¦ä¸­çš„field_mappingsç”Ÿæˆè½¬æ¢æ–¹æ³•
2. å‚è€ƒè¯­ä¹‰åº“ç¡®ä¿è½¬æ¢é€»è¾‘ç¬¦åˆä¸šåŠ¡å«ä¹‰
3. æ‰€æœ‰æ–¹æ³•å¿…é¡»æœ‰é”™è¯¯å¤„ç†
4. ä½¿ç”¨Fakerç”ŸæˆçœŸå®æ•°æ®
5. å·-åŸå¸‚è¦åŒ¹é…ï¼ˆä½¿ç”¨_get_random_state_city()ï¼‰

**è¾“å‡ºæ ¼å¼**:
è¯·è¾“å‡ºå®Œæ•´çš„Pythonä»£ç ï¼ˆå°†3ä¸ªPLACEHOLDERæ›¿æ¢ä¸ºå®é™…ä»£ç ï¼‰ã€‚
ç¡®ä¿ä»£ç å¯ä»¥ç›´æ¥è¿è¡Œï¼Œä¸è¦é—æ¼ä»»ä½•éƒ¨åˆ†ã€‚
            """,
            expected_output="å®Œæ•´çš„Pythonä»£ç ",
            agent=self.agent,
        )

        crew = Crew(agents=[self.agent], tasks=[task], verbose=False)
        result = crew.kickoff()

        # æå–ä»£ç 
        code = result.raw
        if "```python" in code:
            code = code.split("```python")[1].split("```")[0]
        elif "```" in code:
            code = code.split("```")[1].split("```")[0]

        return code.strip()

    def _test_code_smart(
        self, code: str, spec: str, source_path: str, expected_path: str
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨æ™ºèƒ½æµ‹è¯•ç”Ÿæˆå™¨æµ‹è¯•ä»£ç  (V2æ ¸å¿ƒä¼˜åŒ–)
        """
        # è§£æspec
        try:
            spec_dict = json.loads(spec)
        except:
            if "```json" in spec:
                spec = spec.split("```json")[1].split("```")[0]
            elif "```" in spec:
                spec = spec.split("```")[1].split("```")[0]
            spec_dict = json.loads(spec.strip())

        # ç”Ÿæˆæ™ºèƒ½æµ‹è¯•
        test_generator = SmartTestGenerator(spec_dict)
        test_file_content = test_generator.generate_test_file(code)

        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
        test_file = self.output_dir / "_test_runner_v2.py"
        with open(test_file, "w", encoding="utf-8") as f:
            f.write(test_file_content)

        # æ‰§è¡Œæµ‹è¯•
        try:
            result = subprocess.run(
                [sys.executable, "_test_runner_v2.py"],  # åªç”¨æ–‡ä»¶åï¼Œå› ä¸ºcwdå·²ç»è®¾ç½®
                capture_output=True,
                text=True,
                timeout=30,
                cwd=str(self.output_dir),
            )

            if result.returncode == 0:
                # è§£æJSONç»“æœ
                try:
                    test_results = json.loads(result.stdout)
                    return test_results
                except json.JSONDecodeError:
                    return {
                        "success": False,
                        "error_type": "JSONDecodeError",
                        "error_message": "æ— æ³•è§£ææµ‹è¯•ç»“æœ",
                        "stdout": result.stdout,
                        "stderr": result.stderr,
                    }
            else:
                return {
                    "success": False,
                    "error_type": "ExecutionError",
                    "error_message": result.stderr or "æ‰§è¡Œå¤±è´¥",
                    "stdout": result.stdout,
                }

        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "error_type": "TimeoutError",
                "error_message": "æµ‹è¯•æ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰",
            }
        except Exception as e:
            return {
                "success": False,
                "error_type": type(e).__name__,
                "error_message": str(e),
                "traceback": traceback.format_exc(),
            }
        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            if test_file.exists():
                test_file.unlink()

    def _fix_code(self, spec: str, current_code: str, error_result: Dict) -> str:
        """Agentä¿®å¤ä»£ç  (ä¿æŒä¸V1å…¼å®¹)"""
        task = Task(
            description=f"""
ä»£ç æµ‹è¯•å¤±è´¥ï¼Œè¯·åˆ†æé”™è¯¯å¹¶ä¿®å¤ã€‚

**é”™è¯¯ä¿¡æ¯ï¼š**
é”™è¯¯ç±»å‹: {error_result.get("error_type", "Unknown")}
é”™è¯¯æ¶ˆæ¯: {error_result.get("error_message", "No message")}
å †æ ˆè·Ÿè¸ª:
{error_result.get("traceback", "No traceback")[:500]}

**å½“å‰ä»£ç ï¼š**
```python
{current_code[:1000]}
...
```

**åŸå§‹è§„æ ¼ä¹¦ï¼š**
{spec[:500]}...

**ä¿®å¤è¦æ±‚ï¼š**

1. **åˆ†æé—®é¢˜**
   - ä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
   - å®šä½å‡ºé”™çš„ä»£ç è¡Œ
   - ç†è§£ä¸ºä»€ä¹ˆä¼šå‡ºé”™

2. **ä¿®å¤ä»£ç **
   - æœ€å°æ”¹åŠ¨åŸåˆ™ï¼šåªä¿®å¤é”™è¯¯ï¼Œä¸è¦é‡æ„æ•´ä½“ç»“æ„
   - å¦‚æœæ˜¯è¯­æ³•é”™è¯¯ï¼šæ£€æŸ¥æ‹¬å·åŒ¹é…ã€ç¼©è¿›ã€å†’å·ç­‰
   - å¦‚æœæ˜¯é€»è¾‘é”™è¯¯ï¼šä¿®å¤è½¬æ¢é€»è¾‘
   - å¦‚æœæ˜¯å±æ€§/æ–¹æ³•é”™è¯¯ï¼šæ£€æŸ¥æ–¹æ³•åå’Œè°ƒç”¨æ–¹å¼
   - å¦‚æœæ˜¯å¯¼å…¥é”™è¯¯ï¼šæ·»åŠ å¿…è¦çš„importè¯­å¥

3. **ä¿æŒä»£ç é£æ ¼**
   - ä¸åŸæœ‰ä»£ç é£æ ¼ä¿æŒä¸€è‡´
   - ä¿æŒç±»å‹æç¤º
   - ä¿æŒæ³¨é‡Šé£æ ¼

è¯·è¾“å‡ºä¿®å¤åçš„å®Œæ•´ä»£ç ï¼Œç¡®ä¿ä»£ç å¯ä»¥ç›´æ¥è¿è¡Œã€‚
            """,
            expected_output="ä¿®å¤åçš„å®Œæ•´Pythonä»£ç ",
            agent=self.agent,
        )

        crew = Crew(agents=[self.agent], tasks=[task], verbose=False)
        result = crew.kickoff()

        # æå–ä»£ç 
        code = result.raw
        if "```python" in code:
            code = code.split("```python")[1].split("```")[0]
        elif "```" in code:
            code = code.split("```")[1].split("```")[0]

        return code.strip()

    def _execute_final_code(self, code: str) -> List[Dict]:
        """æ‰§è¡Œæœ€ç»ˆä»£ç ç”Ÿæˆæ•°æ® (ä¿æŒä¸V1å…¼å®¹)"""
        exec_file = self.output_dir / "_final_executor_v2.py"

        exec_code = f"""
{code}

import json

if __name__ == "__main__":
    gen = SmartDataGenerator()
    
    # ç”Ÿæˆæ•°æ®
    print("Generating normal cases...")
    normal = gen.generate_normal_cases(10)
    
    print("Generating abnormal cases...")
    abnormal_scenarios = [
        {{"name": "missing_medicare_id", "modifications": {{"MEDICARE_ID": ""}}}},
        {{"name": "invalid_product", "modifications": {{"Product": "INVALID"}}}},
    ]
    abnormal = gen.generate_abnormal_cases(abnormal_scenarios)
    
    print("Generating boundary cases...")
    boundary = gen.generate_boundary_cases(5)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    all_data = normal + abnormal + boundary
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open("generated_data_v2.json", "w", encoding="utf-8") as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)
    
    print(f"Generated {{len(all_data)}} records")
    print("Data saved to generated_data_v2.json")
"""

        with open(exec_file, "w", encoding="utf-8") as f:
            f.write(exec_code)

        # æ‰§è¡Œ
        try:
            # åªä½¿ç”¨æ–‡ä»¶åï¼Œå› ä¸ºcwdå·²ç»æŒ‡å®šäº†ç›®å½•
            exec_filename = "_final_executor_v2.py"
            result = subprocess.run(
                [sys.executable, exec_filename],
                capture_output=True,
                text=True,
                timeout=60,
                cwd=str(self.output_dir),
            )

            if result.returncode == 0:
                # è¯»å–ç”Ÿæˆçš„æ•°æ®
                data_file = self.output_dir / "generated_data_v2.json"
                if data_file.exists():
                    with open(data_file, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    return data
                else:
                    print("Warning: Data file not found")
                    return []
            else:
                print(f"Execution error: {result.stderr}")
                return []

        except Exception as e:
            print(f"Error executing final code: {e}")
            return []
        finally:
            # æ¸…ç†æ‰§è¡Œæ–‡ä»¶
            if exec_file.exists():
                exec_file.unlink()


if __name__ == "__main__":
    # æµ‹è¯•è¿è¡Œ
    print("æµ‹è¯•è‡ªä¸»ä»£ç ç”Ÿæˆå™¨ V2...")

    generator = AutonomousCodeGeneratorV2(max_iterations=3)

    result = generator.run(
        rules_path="case/rules.xlsx",
        source_path="case/source.csv",
        expected_path="case/expected.txt",
    )

    if result["success"]:
        print(f"\nâœ… æˆåŠŸï¼è¿­ä»£ {result['iterations']} æ¬¡ (V2)")
        print(f"ğŸ“„ ä»£ç ä¿å­˜äº: {result['code_path']}")
        print(f"ğŸ“Š ç”Ÿæˆæ•°æ®: {len(result['data'])} æ¡")
    else:
        print(f"\nâŒ å¤±è´¥: {result.get('error', 'Unknown error')}")
